{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abc159cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification, BartTokenizer, BartForConditionalGeneration\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import spacy\n",
    "import pytextrank\n",
    "import en_core_web_sm\n",
    "import re\n",
    "import sys\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "import time\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea667285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f7b12a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# punctuation model\n",
    "model_p = PunctuationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7a9eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "condi_gen = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1df1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(files):\n",
    "    \"\"\" returns file names in the folder\"\"\"\n",
    "    file_names = []\n",
    "    for file in files:\n",
    "        file_names.append(glob.glob(file))\n",
    "    file_names = list(itertools.chain.from_iterable(file_names))\n",
    "    return file_names\n",
    "\n",
    "def make_summary_f(text, max_length, min_length):\n",
    "    \"\"\" use the facebook model to get a summary\"\"\"\n",
    "    sum_list = summarizer(text, min_length=min_length, max_length = max_length, do_sample=False)\n",
    "    string = next(iter(sum_list[0].items()))[1]\n",
    "    \n",
    "    return string\n",
    "\n",
    "def punct_model(text):\n",
    "    \"\"\"punctuate the text\"\"\"\n",
    "    return(model_p.restore_punctuation(text))\n",
    "\n",
    "def text_rank(text):\n",
    "    \"\"\" use text rank to rank the phrases\"\"\"\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    nlp.add_pipe('textrank', last=True)\n",
    "    doc = nlp(text)\n",
    "    str_arr = []\n",
    "    for string in doc._.textrank.summary(limit_phrases=5, limit_sentences=1):\n",
    "        str_arr.append(string)\n",
    "    return str_arr[0].text\n",
    "\n",
    "def model(text, run_text_rank, fb_length, min_len):\n",
    "    \"\"\" run_text_rank is a bool, true if text rank should be\n",
    "        used in the model. Set length for make_summary_f\"\"\"\n",
    "    if len(text)<150:\n",
    "        return text\n",
    "    if run_text_rank:\n",
    "        temp =  text_rank(text)\n",
    "        return make_summary_f(temp,fb_length, min_len)\n",
    "    \n",
    "    return make_summary_f(text, fb_length, min_len)\n",
    "\n",
    "def short_min(text):\n",
    "    \"\"\"\n",
    "    cut text to first punctuation mark\n",
    "    \"\"\"\n",
    "    symbols = [\".\",\";\"]\n",
    "    arr = []\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    for char in text:\n",
    "        if char in symbols:\n",
    "            counter+=1\n",
    "            arr.append((char, i))\n",
    "        i+=1\n",
    "        \n",
    "    min_val = sys.maxsize\n",
    "    for tup in arr:\n",
    "        if min_val>tup[1]:\n",
    "            min_val = tup[1]\n",
    "    \n",
    "    #if you have a good sentence of the right size return it\n",
    "    return text[0:min_val]\n",
    "\n",
    "def check_str(text,l,u):\n",
    "    \"\"\" give lower and upper bounds and return true or false\n",
    "        if the text is within the range\"\"\"\n",
    "    if text == 0:\n",
    "        return False\n",
    "    elif len(text)<=u and len(text)>=l:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def shorten_string(text):\n",
    "    \"\"\"\n",
    "    cut text to closest punctuation mark to 80 characters\n",
    "    \"\"\"\n",
    "    symbols = [\".\",\";\"]\n",
    "    arr = []\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    #get all locations of the punctuations\n",
    "    for char in text:\n",
    "        if char in symbols:\n",
    "            counter+=1\n",
    "            arr.append((char, i))\n",
    "        i+=1\n",
    "        \n",
    "    min_val = sys.maxsize\n",
    "    for tup in arr:\n",
    "        if min_val>tup[1]:\n",
    "            min_val = tup[1]\n",
    "    \n",
    "    i = 0\n",
    "    up_bound = 0\n",
    "    low_bound = 0\n",
    "    # get punctuations closest to character 90\n",
    "    while i<len(arr):\n",
    "        if up_bound !=0 and low_bound !=0:\n",
    "            break\n",
    "        elif arr[i][1]>=90:\n",
    "            up_bound = arr[i][1]\n",
    "            low_bound = arr[i-1][1]\n",
    "        i+=1\n",
    "    #print(arr)\n",
    "    #print(up_bound, low_bound)\n",
    "    \n",
    "    difu = abs(up_bound-90)\n",
    "    difl = abs(low_bound-90)\n",
    "    diful = up_bound-low_bound\n",
    "    \n",
    "    # if the upper and lower bounds are close\n",
    "    if up_bound !=0:\n",
    "        #shorten to upper bound if the difference between them is small\n",
    "        # or the upper bound is smaller than the lower bound or the lower bound\n",
    "        # is 35 or less\n",
    "        if diful<=5 or difu<=difl or difl<35:\n",
    "            short_string = text[0:up_bound]\n",
    "            return short_string\n",
    "        elif difu>=difl:\n",
    "            short_string = text[0:low_bound]\n",
    "            return short_string\n",
    "    \n",
    "    return text[0:min_val]\n",
    "    \n",
    "def check_stops(text):\n",
    "    \"\"\"return how many full stops in the text\"\"\"\n",
    "    symbols = [\".\"]\n",
    "    counter = 0\n",
    "    for char in text:\n",
    "        if char == \".\":\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def similar(len1, len2):\n",
    "    # find out if 2 texts are similar in length\n",
    "        if abs(len1-len2)<=3:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def cut(a, l, u, grp):\n",
    "    if len(a)<150:\n",
    "        return str(a)\n",
    "    # check if the model gives a suitable summary\n",
    "    \n",
    "    # shorten the text to the first punctuation and see if it meets the criteria    \n",
    "    temp_f = short_min(a)\n",
    "\n",
    "    # shorten the text to the punctutation mark closest to 80 characters and see if it\n",
    "    # meets the criteria\n",
    "    temp_e = shorten_string(a)\n",
    "    \n",
    "    # add punctuation to the SHORTENED TEXT to FIRST punctuation. \n",
    "    # shorten it again to the FIRST punctuation and check if it meets the criteria\n",
    "    punct_temp_f = punct_model(temp_f)\n",
    "    temp_fpf = short_min(punct_temp_f)\n",
    "\n",
    "    # add punctuation to the SHORTENED TEXT to FIRST punctuation.\n",
    "    # shorten it again to the 80TH punctuation and check if it meets the criteria\n",
    "    temp_fpe = shorten_string(punct_temp_f)\n",
    "\n",
    "    # add punctuation to the SHORTENED TEXT to 80TH punctuation.\n",
    "    # shorten it again to the FIRST punctuation and check if it meets the criteria\n",
    "    punct_temp_e = punct_model(temp_e)\n",
    "    temp_epf = short_min(punct_temp_e)\n",
    "\n",
    "    # add punctuation to the SHORTHENED TEXT to 80TH punctuation.\n",
    "    # shorten it again to the 80TH punctuation and check if it meets the criteria\n",
    "    temp_epe = shorten_string(punct_temp_e)\n",
    "\n",
    "    # add punctuaction to the TEXT and shorten it to the FIRST punctuation\n",
    "    punct_temp_t = punct_model(a)\n",
    "    temp_tpf = short_min(punct_temp_t)\n",
    "\n",
    "    # add punctuation to the TEXT and shorten it to the 80TH punctuation\n",
    "    temp_tpe = shorten_string(punct_temp_t)\n",
    "\n",
    "    summaries = []\n",
    "    lengths = []\n",
    "    summaries.extend([a, temp_f, temp_e, temp_fpf, temp_fpe, temp_epf, temp_epe, temp_tpf, temp_tpe])\n",
    "    lengths.extend([len(a), len(temp_f), len(temp_e), len(temp_fpf), len(temp_fpe), len(temp_epf)\n",
    "                    , len(temp_epe), len(temp_tpf), len(temp_tpe)])\n",
    "    \n",
    "    summaries.sort()\n",
    "    lengths.sort()\n",
    "    i = len(summaries)-1\n",
    "    while i>0:\n",
    "        if not similar(lengths[i],lengths[8]) and check_str(summaries[i],l,u):\n",
    "            return str(summaries[i])\n",
    "        elif not similar(lengths[i],lengths[8]) or check_str(summaries[i],l,u):\n",
    "            return str(summaries[i])\n",
    "        i-=1\n",
    "    \n",
    "    return str(summaries[8])\n",
    "\n",
    "def loc_full(text):\n",
    "    \"\"\" \n",
    "    Get all locations of full stops\n",
    "    \"\"\"\n",
    "    symbols = [\".\"]\n",
    "    arr = []\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    #get all locations of the punctuations\n",
    "    for char in text:\n",
    "        if char in symbols:\n",
    "            counter+=1\n",
    "            arr.append((char, i))\n",
    "        i+=1\n",
    "    return arr\n",
    "\n",
    "def split_paragraph(text):\n",
    "    \"\"\"\n",
    "    input a text and split it up into num_para paragraphs. num_para should\n",
    "    be more than one since the default of the model is 1 paragraph\n",
    "    \"\"\"\n",
    "\n",
    "    locations = loc_full(text)\n",
    "    num_para = len(locations)\n",
    "    if num_para<2:\n",
    "        return [text]\n",
    "    new_string = \"\"\n",
    "    j = 0\n",
    "    arr = []\n",
    "    while j<num_para:\n",
    "        new_string = str(text[0:locations[j][1]] +  \" \\n\" + text[locations[j][1]:])\n",
    "        arr.append(new_string)\n",
    "        #print(new_string)\n",
    "        #print(locations)\n",
    "        j+=1\n",
    "    return arr\n",
    "\n",
    "def new_model(text):\n",
    "    input_tokens = tokenizer.batch_encode_plus([text], return_tensors = \"pt\", max_length = 1024, truncation =True)[\"input_ids\"]\n",
    "    num_token = input_tokens.shape[1]\n",
    "    min_ = int(0.3*num_token)\n",
    "    max_ = int(0.7*num_token)\n",
    "\n",
    "    encoded_ids = condi_gen.generate(input_tokens, max_length = max_, min_length = min_, num_beams = 4,\n",
    "                                early_stopping = True)\n",
    "    summary = tokenizer.decode(encoded_ids.squeeze(), skip_special_tokens = True)\n",
    "    return textwrap.fill(summary,max_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "751d6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [\"Json files/*.json\"]\n",
    "json_files = get_filenames(path)\n",
    "i=0\n",
    "\n",
    "desc = \"PROBLEM DESCRIPTION \"\n",
    "target = \"TARGET CONDITION \"\n",
    "current = \"CURRENT CONDITION \"\n",
    "root = \"ROOT CAUSE ANALYSIS \"\n",
    "counter = \"COUNTERMEASURES \"\n",
    "effect = \"EFFECT CONFIRMATION \"\n",
    "follow = \"FOLLOW UP ACTION \"\n",
    "long_strs = []\n",
    "#print(len(json_files))\n",
    "while i < len(json_files):\n",
    "    f = open(json_files[i])\n",
    "    dicts = json.load(f)\n",
    "    for vals in dicts.values():\n",
    "        for val in vals.items():\n",
    "            l = 40\n",
    "            u = 150\n",
    "            if val[0] == \"PROBLEM DESCRIPTION\":\n",
    "                desc += val[1]\n",
    "            elif val[0] == \"TARGET CONDITION\":\n",
    "                target+=val[1]\n",
    "            elif val[0] == \"CURRENT CONDITION\":\n",
    "                current += val[1]\n",
    "            elif val[0] == \"ROOT CAUSE ANALYSIS\":\n",
    "                root+=val[1]\n",
    "            elif val[0] == \"COUNTERMEASURES\":\n",
    "                counter +=val[1]\n",
    "            elif val[0] == \"EFFECT CONFIRMATION\":\n",
    "                effect+=val[1]\n",
    "            elif val[0] == \"FOLLOW UP ACTION\":\n",
    "                follow+=val[1]\n",
    "                #g.write(\"\\n\")\n",
    "                #a = model(val[1], False, 53)\n",
    "                #g.write(cut(a,l,u,val[0]))\n",
    "    i+=1\n",
    "#print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a77df22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEM DESCRIPTION WO# K150-08, Deka 10 TP1008 DV dynamic lean shift failure observed In RSG E-10 test bench mechanical durability per S1297 Injectors were manufactured in Prototype Services May 29, 2019. Configuration: 12.55mm OD,Extra Short, 10mm Tip, Schaleger MPG, NPN ATB, NPN LSSBMW complained first issues 07/2018 (19.07.) @plant Dingolfing (Hr. Habold MUC). There're no specific OBD failure code. The failure appears after first SCR system initiation (F1_Test). Failed at test step: System leak test. Service 31 ID 0x301 Detailed failure description see attachment (EINFÜGEN!).1) What vehicle CN7/CN7a 2) Product SIM3K-541, SW version 6VA600 3) Who issued HMMA QC 4) How HMMA QC reported that '5' instead of 'D' was displayed for the select lever switch information via UDS $22 in Roll &Brake process of CN7 vehicle. And compared to the project Nu ATK CVT, different value was displayed for D range. 5) Containment action 9,124EA to be reprogrammed in HMMA plantInjectors mechanically inoperable after 400 cycles of thermal shock, functional issues noted since 100 cycles TP 7072: M084U28120 M084U29625, TP7363: M085K27336 Containment Action - NPN - within Validation09.07. BMW (Rolls Royce) communicated an issue @plant Goodwood. Problem only with D-sample ECU together with 18-07-530 B88 software and affected datasets concerning the synchronization of the immobilizer (EWS elektronische Wegfahrsperre); key is not writeable with any tooling anymore. Further investigation showed that the re-programming of the ECU (MSD87 - 12 cylinder) is not possible anymore for some dataset variants of the SW B88 (e.g.: RR4 US BB / RR5 US / RR6 US BB).Spray angle ranging from 36,7° to 69,0°O PV parts (spec allow 70°+25°)When: On Dec.5th.2018, CAF CQ3 found one piece injector stuck open during vehicle testing. What: The chips from VB was found in the seat sealing area after tear down injector on Dec. 11st.2018 Which supplier of VB: Asimco Beijing Picture 1 2 - Containment action: Dec.10th.2018: Fast response to customer and send back the suspected part. 100% VB sorting in CGQ plant and supplier side. No chips part wasSporadic CAN frame dropouts existing in Pre-SW-versions of SE1500. This leads to a sporadic dropout of Message ESP21 and triggers toggling of vs SAE (raw value of vehicle speed), which leads to alternating values between 0 and 255 (replacement/substitute value).\n",
      "TARGET CONDITION Twenty four of twenty-four injectors successfully pass test bench mechanical durability per S1297 in RSG E-10Failure root cause has to be understood and failure occurrence has to be eliminated. Target is to bring F1_testfails to zero % at customer plants1) Target Customer requirement delivered at Nu ATK project $01A0 in UDS $22 service D is defined by '8'. Select Lever Switch Displayed via GDS after changing Manual Mode 12- Product functionality remains post air-air thermal shock testingGoal is to analyze the ECU hardware and the affected B88 software and the calibration data to fix both issues (immobilizer sync & reprogramming).All parts produced within 70°+25° specificationConfirm the root cause in supplier side and implement prevention action in production line. B. Find Root cause of Problem / IssueIdentify the root cause of CAN frame / ESP21 dropouts and the the location of the failure (VT side or VW side). If failure is on VT side define timing for problem solution (SW correction) and allign it with overall SW timing for SE1500/SE1550, depending on severity of the problem\n",
      "CURRENT CONDITION Specification (+5% / -3%) 200M Audit: 47362 = -10.1%, 47371 = -6.2%, 47384 = -6.1% 300M Audit: 4742 2= -6.7%, 47421 = -3.3% *Reference 8D ES191216231144 for additional dynamic lean failuresAll BMW plants (using SCR systems) are infected, also all variants (using SCR system). After some minutes the test can be repeated without the failure. BMW decided to send the cars out. Just one system affected were the second test was also not ok. this system will be send to RGB.1) Current $01A0 in UDS $22 service D is defined by '5'. Lever Switch Displayed via GDS before changing 2) Impact: Roll and brake test in customer plant cannot be passed due to wrong gear information from TCUDeka 7 transfer for CGQ Thermal Shock test S1331 500 Shocks; Qd +4/-4% Shift from baseline TP7072 - ER1149 (WO#M123-02), TP7363 - ER1150 (WO#M123-08) Short Standard tipInitial status: An analysis of locked ECUs showed that only SW variants which have an activated anti jerk function are affected. BMW Customer part#: 9453018-01 (SW 9SP9B88S) Upd. 13th of July: Customer updated all data variants of the SW B88 with calibration workaround and deactivated anti jerk function. Upd. 18th of July: One cycle resume command of the controller enable the flash protection during start up and locked the ECU; SW update planned for SW C00 in CW31 (activation of anti jerk is possible again).Out of specification spray angle for DDU transfer PV parts, Specification allows 70°+25°, parts observed as low as 36° Situation pertains to both GM and HMC parts produced for transfer PV, but not to Ford parts No containment needed - parts not being produced for customer, only for PVSporadic CAN frame dropouts existing in Pre-SW-versions of SE1 Delivery of SW SE1500 to customer VW stopped\n",
      "ROOT CAUSE ANALYSIS Reference 8D ES 191216231144 for detailed analysis of root cause hypotheses of design robustness RCH2 - Deka 10 design and process variation introduces inherent variability, resulting in isolated occurrences dynamic lean shift observation Why does dynamic lean shift occur in a percentage of the test population? Dynamic lean shift occurs due to an increase in opening time, and variation in opening time is seen part to part Why does opening time variation occur? Opening time variation is a resultant of variation in wear severity at the sealing interface Why is variation seen in ball to seat sealing band wear? Wear variation is a resultant of design robustness sensitivity to design and process parameter variation Why was variation of design and process parameters influence on dynamic shift not captured in Deka 10 CTG 8D S180711224450? Overall variation in small controlled builds not captured, resulting in small occurrence of flow shift being observed outside of the defined specification due to sensitivity and lack of robustness against the stack-upComponents/systems analysis: TFM/System: Drop of pressure partly reproduceable at RBG testbench since 28.09.2018, but pressure values are still in tolerance and therefore the system leaktest is passed. During this test only the returned TFM was used and therefore the rootcause could be located to the TFM module. RDU: First part was NTF; cleanliness analysis t.b.d CW 40 To be clarified Is there any connection between failure re-occurrence and time between first and second Components analysis in consideration of failure description (leakage, damages, Full pump characterization cw40 to locate source of symptom Optimization of BMW test to be proved. Please consider the additional \"fault tree file\" and presentation ,,DD additional docs\".in Nu ATK CVT Spec was only SWCN canceled Why Why Why Wrong managem spec and sw) wrong value was not set back value from $22 service Spec ewed was with not revi reference for UDS Why for not used to review er requirement 6VA project Customer require d based on spec for the test- RCH1: Handling damage - No visual damage found on inspection Not RCH RCH2: Issue with Exsol D40 used as calibration fluid Not RCH (review FTIR results) RCH3 Contamination introduced in assembly process -> Not RCH Injector M085K27336 was sumberged in n-Heptane for 24 hours, post soak injector returned to nominal flow values RCH4: Fluid introduced post injector assembly Primary RCH RCH4.1: Functional Bench Fluid - Not RCH RCH4.2: O-ring lubrication -> Confirmed RCH Mineral oil confirmed to match residue observed within stuck injectors IN-062802/IN-062803 (cell 6/cell 7) instructs technician to lightly lubricate upper injector oring prior to insertion in test headTrigger is \"anti jerk\" function that activates flash protection and it is not possible to reprogram the ECU Only D-samples (serial parts) are affected. Some flash containers of SW version B86 to B88 show this behavior (BMW stated). Continental analysis of the various effected vehicle variants (e.g.: RR4 US BB / RR5 US / RR6 US BB) gave a hint to some special calibration data variant (activation of anti jerk function). BMW confirmed this finding with a crosscheck (deactivation of anti jerk function) in an affected calibration variant. To understand the root cause debugging of a D-sample ECU is necessary. A new ECU with Lauterbach access has to be built up for debugging. A changed S-Boot is necessary for debugger access. Switch is necessary to disable the Monitoring Unit (MU) and the Watchdog (WD). Debugging showed an issue that occurs due to copy process of the flash memory which is necessary for application ECUs but not for serial ECU samples. This process caused an Single Cycle Resume Command, which enables the Flash Protection. Therefore at least on one of the four addresses A0045554 / A0055554 A0065554 / A0075554 must have the value \"5E\" so that the flash protection is activated. One of these four addresses is used by the anti jerk function.Supplier change for DDU lower housing (LH) (NPN components Texeido) and obsolete machinery used to produce the part resulted in the update of certain LH print dimensions to reduce leak failures. This resulted in a valve that was more recessed inside the LH than normal NPN production parts and the risk of having some parts out of spec for spray cone angle. )These parts are identified as Loop 1) This issue was able to be turned on and off by varying the amount by which the valve wasCause 1: One pcs of debug part was mixed into good parts by debug technician. Check the FTQ ( scrap record), only one piece (chips defect) part is missed in the record. Suspect part was produced on Jun.26.2018 in supplier side, the equipment manufacturer did the annual calibration on that day according to record on that day. Cause 2: Incorrect the length of drilling tool during debug Repeat the same failure mode with incorrect length 53.29mm of drilling tool The chip occur after change the length of tool. Cause 3: Visual check WI did not clearly specify this defect location and boundary samples. There are risky the operator skip the NG part during inspection. A al inspection operator A Cleaning operator Final inspector miss the defect part Cleaning process External technician mix the debug part VB chip (Why happened?( (Occur path)Debugging Session identifies that the restbus simulation, delivery from customer VW, is the main root cause for toggling of the ESP_21 Message. Here the ESP_21 message is sent 3 times in a row within timing of overall - 10ms. Regular/correct case would be here that a message transfer every 20ms is present (only one event/message per 20ms). @ - 412317 CAN E4 ESP_21_SOK_Signatur_SOK_XIX_E3V_ACANFD 429913 CAN FD SP_21_XIX_E3V_ACANFD 430361 CAN : E4 ESP_21_SOK_Signatur_SOK_XIX_E3V_ACANFI 449567 CAN 1 FD ESP_21_XIX__E3V_ACANFD CAN 1 E4 ICAS(TX) ASG 2.2 (RX): Message CAN ESP_21_XIX_E3V_ACANFD ICAS(TX) Message CAN FD SP_21_XIX_E3V_ACANFD ICAS(TX) ASG 2.2 (RX): Message ICAS(TX) ASG 2.2 (RX): Signature 1 ICAS(TX ASG 2.2 (RX): Signature 2 19.531318 E4 ICAS(TX) ASG 2.2 (RX): Signature 3 19.533198 CAN 1 E4 CAN : FD ESP_21_XIX_E3V_ACANFD 19.535459 CAN 1 E4 ESP_21_SOK_Signatur_SOK_XIX_E3V_ACAN CAN 1 FD ESP_21_XIX_E3V_ACANFD 19.551877 CAN 1 E4 ESP_21_SOK_Signatur_SOK_XIX_E3V_ACANFD\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [42], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(string\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m     10\u001b[0m min_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.3\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(string\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m---> 11\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m g\u001b[38;5;241m.\u001b[39mwrite(cut(a,l,u))\n\u001b[0;32m     13\u001b[0m g\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [35], line 37\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m(text, run_text_rank, fb_length, min_len)\u001b[0m\n\u001b[0;32m     34\u001b[0m     temp \u001b[38;5;241m=\u001b[39m  text_rank(text)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m make_summary_f(temp,fb_length, min_len)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_summary_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfb_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_len\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [35], line 11\u001b[0m, in \u001b[0;36mmake_summary_f\u001b[1;34m(text, max_length, min_length)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_summary_f\u001b[39m(text, max_length, min_length):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124;03m\"\"\" use the facebook model to get a summary\"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     sum_list \u001b[38;5;241m=\u001b[39m \u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(sum_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()))[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m string\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:235\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:137\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m    142\u001b[0m     ):\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1074\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1080\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1081\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1082\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m    989\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 990\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m    991\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:159\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_length)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m], generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 159\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    160\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_utils.py:1207\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[0;32m   1201\u001b[0m         inputs_tensor, pad_token_id, eos_token_id\n\u001b[0;32m   1202\u001b[0m     )\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;66;03m# 4. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_utils.py:524\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[0;32m    522\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    523\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 524\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:803\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[1;32m--> 803\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n\u001b[0;32m    806\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm_embedding(hidden_states)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:139\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[1;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[0;32m    134\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    135\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m    136\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    137\u001b[0m )\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2195\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "long_strs = np.array([desc, target, current, root, counter, effect, follow])\n",
    "start = time.time()\n",
    "\n",
    "with open('jsons.txt', 'a') as g:\n",
    "    for string in long_strs:\n",
    "        print(string)\n",
    "        l = 40\n",
    "        u = 150\n",
    "        max_len = int(0.8*len(string.split(\" \")))\n",
    "        min_len = int(0.3*len(string.split(\" \")))\n",
    "        a = model(string, False,max_len, min_len)\n",
    "        g.write(cut(a,l,u))\n",
    "        g.write(\"\\n\")\n",
    "f.close()\n",
    "end = time.time()\n",
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67ddbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"input\", \"output\", \"output_length\", \"input_length\", \"model_name\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17721957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of decoder_input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [70], line 22\u001b[0m\n\u001b[0;32m     15\u001b[0m min_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.3\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(val[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#g.write(\"\\ninputs\\n\")\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#g.write(\"\\n\"+val[1]+\"\\n\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#g.write(val[0])\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#print(val[0],val[1])\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#g.write(\"\\n\")\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#split_string = split_paragraph(val[1])\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mnew_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#g.write(\"\\noutputs\\n\")\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#g.write(a)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#g.write(\"\\n\")\u001b[39;00m\n\u001b[0;32m     26\u001b[0m arr \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn [52], line 238\u001b[0m, in \u001b[0;36mnew_model\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    235\u001b[0m min_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.3\u001b[39m\u001b[38;5;241m*\u001b[39mnum_token)\n\u001b[0;32m    236\u001b[0m max_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.7\u001b[39m\u001b[38;5;241m*\u001b[39mnum_token)\n\u001b[1;32m--> 238\u001b[0m encoded_ids \u001b[38;5;241m=\u001b[39m \u001b[43mcondi_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(encoded_ids\u001b[38;5;241m.\u001b[39msqueeze(), skip_special_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m textwrap\u001b[38;5;241m.\u001b[39mfill(summary,max_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_utils.py:1385\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1382\u001b[0m         input_ids, expand_size\u001b[38;5;241m=\u001b[39mnum_beams, is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[0;32m   1383\u001b[0m     )\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;66;03m# 12. run beam search\u001b[39;00m\n\u001b[1;32m-> 1385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_search(\n\u001b[0;32m   1386\u001b[0m         input_ids,\n\u001b[0;32m   1387\u001b[0m         beam_scorer,\n\u001b[0;32m   1388\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m   1389\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1390\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mpad_token_id,\n\u001b[0;32m   1391\u001b[0m         eos_token_id\u001b[38;5;241m=\u001b[39meos_token_id,\n\u001b[0;32m   1392\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39moutput_scores,\n\u001b[0;32m   1393\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1394\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1395\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1396\u001b[0m     )\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[0;32m   1399\u001b[0m     \u001b[38;5;66;03m# 10. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(\n\u001b[0;32m   1401\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[0;32m   1402\u001b[0m         top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         renormalize_logits\u001b[38;5;241m=\u001b[39mrenormalize_logits,\n\u001b[0;32m   1407\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_utils.py:2319\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2316\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2317\u001b[0m             this_peer_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 2319\u001b[0m sequence_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_scorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2320\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2325\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate:\n\u001b[0;32m   2331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_scores:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_beam_search.py:372\u001b[0m, in \u001b[0;36mBeamSearchScorer.finalize\u001b[1;34m(self, input_ids, final_beam_scores, final_beam_tokens, final_beam_indices, max_length, pad_token_id, eos_token_id, beam_indices)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# fill with hypotheses and eos_token_id if the latter fits in\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (hypo, best_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(best, best_indices)):\n\u001b[1;32m--> 372\u001b[0m     \u001b[43mdecoded\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msent_lengths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m hypo\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m         indices[i, : \u001b[38;5;28mlen\u001b[39m(best_idx)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(best_idx)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [2]"
     ]
    }
   ],
   "source": [
    "\n",
    "path = [\"Json files/*.json\"]\n",
    "json_files = get_filenames(path)\n",
    "i=0\n",
    "with open('jsons2.txt', 'a') as g:\n",
    "    while i < len(json_files):\n",
    "        f = open(json_files[i])\n",
    "        dicts = json.load(f)\n",
    "        for vals in dicts.values():\n",
    "            for val in vals.items():\n",
    "                l = 40\n",
    "                u = 150\n",
    "                if val[0] == \"PROBLEM DESCRIPTION\" or val[0] == \"TARGET CONDITION\" or val[0] == \"CURRENT CONDITION\" or val[0] == \"ROOT CAUSE ANALYSIS\" or val[0] == \"COUNTERMEASURES\" or val[0] == \"EFFECT CONFIRMATION\" or val[0] == \"FOLLOW UP ACTION\":\n",
    "                    start = time.time()\n",
    "                    max_len = int(0.8*len(val[1].split(\" \")))\n",
    "                    min_len = int(0.3*len(val[1].split(\" \")))\n",
    "                    #g.write(\"\\ninputs\\n\")\n",
    "                    #g.write(\"\\n\"+val[1]+\"\\n\")\n",
    "                    #g.write(val[0])\n",
    "                    #print(val[0],val[1])\n",
    "                    #g.write(\"\\n\")\n",
    "                    #split_string = split_paragraph(val[1])\n",
    "                    a = new_model(val[1])\n",
    "                    #g.write(\"\\noutputs\\n\")\n",
    "                    #g.write(a)\n",
    "                    #g.write(\"\\n\")\n",
    "                    arr = []\n",
    "                    #for j in split_string:\n",
    "                        #b = model(j,False,max_len, min_len)\n",
    "                        \n",
    "                        #b = new_model(j)\n",
    "                        #g.write(\"\\noutputs\\n\")\n",
    "                        #g.write(b)\n",
    "                        #a = str(val[0] + \": \" + b)\n",
    "                    if len(b)<5:\n",
    "                        #arr.append(val[1])\n",
    "                        g.write(val[1])\n",
    "                        #else:\n",
    "                            #g.write(a)\n",
    "                            #c = cut(b,l,u,val[0])\n",
    "                            #arr.append(c)\n",
    "                            #g.write(cut(b,l,u,val[0]))\n",
    "                        #g.write(\"\\n\")\n",
    "                    end =  time.time()\n",
    "                    df.loc[len(df)] = [val[1], a, len(a), len(val[1]), \"uncut_unsplit_80_false_4\", end-start]\n",
    "                            \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0b73917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>output_length</th>\n",
       "      <th>input_length</th>\n",
       "      <th>model_name</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO# K150-08, Deka 10 TP1008 DV dynamic lean sh...</td>\n",
       "      <td>WO# K150-08, Deka 10 TP1008 DV dynamic lean sh...</td>\n",
       "      <td>90</td>\n",
       "      <td>266</td>\n",
       "      <td>cut_split_dynamic_false</td>\n",
       "      <td>4.753284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specification (+5% / -3%) 200M Audit: 47362 = ...</td>\n",
       "      <td>200M Audit: 47362 = -10.1%, 47371 = -6.2%, 47</td>\n",
       "      <td>45</td>\n",
       "      <td>189</td>\n",
       "      <td>cut_split_dynamic_false</td>\n",
       "      <td>9.356972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twenty four of twenty-four injectors successfu...</td>\n",
       "      <td>Twenty four of twenty-four injectors successfu...</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>cut_split_dynamic_false</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reference 8D ES 191216231144 for detailed anal...</td>\n",
       "      <td>RCH2 - Deka 10. design and process variation i...</td>\n",
       "      <td>145</td>\n",
       "      <td>1061</td>\n",
       "      <td>cut_split_dynamic_false</td>\n",
       "      <td>5.075427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO# K150-08, Deka 10 TP1008 DV dynamic lean sh...</td>\n",
       "      <td>WO# K150-08, Deka 10 TP1008 DV dynamic lean sh...</td>\n",
       "      <td>204</td>\n",
       "      <td>266</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>4.080085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Specification (+5% / -3%) 200M Audit: 47362 = ...</td>\n",
       "      <td>Specification (+5% / -3%) 200M Audit: 47362 = ...</td>\n",
       "      <td>108</td>\n",
       "      <td>189</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>4.110008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Twenty four of twenty-four injectors successfu...</td>\n",
       "      <td>Twenty four of\\ntwenty-four\\ninjectors\\nsucces...</td>\n",
       "      <td>91</td>\n",
       "      <td>109</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>1.311477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Reference 8D ES 191216231144 for detailed anal...</td>\n",
       "      <td>RCH2 - Deka 10 design and process variation in...</td>\n",
       "      <td>352</td>\n",
       "      <td>1061</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>6.824746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1. Review of defined dynamic tolerance vs syst...</td>\n",
       "      <td>1. Review of defined dynamic tolerance vs syst...</td>\n",
       "      <td>194</td>\n",
       "      <td>544</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>3.422844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AMC PV6 (L062-05) PV8 (L113-03) and PV9 (L209-...</td>\n",
       "      <td>AMC PV6 (L062-05) PV8 (L113-03) and PV9 (L209-...</td>\n",
       "      <td>179</td>\n",
       "      <td>348</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>4.434141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Reference 8D ES191216231144 for follow up actions</td>\n",
       "      <td>Reference\\n8D\\nES19121623</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>0.768943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BMW complained first issues 07/2018 (19.07.) @...</td>\n",
       "      <td>BMW complained first issues 07/2018 (19.07.) @...</td>\n",
       "      <td>198</td>\n",
       "      <td>300</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>4.297503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>All BMW plants (using SCR systems) are infecte...</td>\n",
       "      <td>All BMW plants (using SCR systems) are\\ninfect...</td>\n",
       "      <td>147</td>\n",
       "      <td>281</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>2.552174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Failure root cause has to be understood and fa...</td>\n",
       "      <td>Failure root cause has\\nto be understood and\\n...</td>\n",
       "      <td>104</td>\n",
       "      <td>145</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>1.603712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Components/systems analysis: TFM/System: Drop ...</td>\n",
       "      <td>TFM/System: Drop of pressure partly reproducea...</td>\n",
       "      <td>259</td>\n",
       "      <td>742</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>5.255943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alignment with customer is to increase the cur...</td>\n",
       "      <td>Software validation performed and passed. Cali...</td>\n",
       "      <td>173</td>\n",
       "      <td>318</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>3.105693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Software validation performed and passed. For ...</td>\n",
       "      <td>Software validation performed and passed. For ...</td>\n",
       "      <td>170</td>\n",
       "      <td>388</td>\n",
       "      <td>uncut_unsplit_80_false_4</td>\n",
       "      <td>3.019922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input  \\\n",
       "0   WO# K150-08, Deka 10 TP1008 DV dynamic lean sh...   \n",
       "1   Specification (+5% / -3%) 200M Audit: 47362 = ...   \n",
       "2   Twenty four of twenty-four injectors successfu...   \n",
       "3   Reference 8D ES 191216231144 for detailed anal...   \n",
       "4   WO# K150-08, Deka 10 TP1008 DV dynamic lean sh...   \n",
       "5   Specification (+5% / -3%) 200M Audit: 47362 = ...   \n",
       "6   Twenty four of twenty-four injectors successfu...   \n",
       "7   Reference 8D ES 191216231144 for detailed anal...   \n",
       "8   1. Review of defined dynamic tolerance vs syst...   \n",
       "9   AMC PV6 (L062-05) PV8 (L113-03) and PV9 (L209-...   \n",
       "10  Reference 8D ES191216231144 for follow up actions   \n",
       "11  BMW complained first issues 07/2018 (19.07.) @...   \n",
       "12  All BMW plants (using SCR systems) are infecte...   \n",
       "13  Failure root cause has to be understood and fa...   \n",
       "14  Components/systems analysis: TFM/System: Drop ...   \n",
       "15  Alignment with customer is to increase the cur...   \n",
       "16  Software validation performed and passed. For ...   \n",
       "\n",
       "                                               output  output_length  \\\n",
       "0   WO# K150-08, Deka 10 TP1008 DV dynamic lean sh...             90   \n",
       "1       200M Audit: 47362 = -10.1%, 47371 = -6.2%, 47             45   \n",
       "2   Twenty four of twenty-four injectors successfu...            109   \n",
       "3   RCH2 - Deka 10. design and process variation i...            145   \n",
       "4   WO# K150-08, Deka 10 TP1008 DV dynamic lean sh...            204   \n",
       "5   Specification (+5% / -3%) 200M Audit: 47362 = ...            108   \n",
       "6   Twenty four of\\ntwenty-four\\ninjectors\\nsucces...             91   \n",
       "7   RCH2 - Deka 10 design and process variation in...            352   \n",
       "8   1. Review of defined dynamic tolerance vs syst...            194   \n",
       "9   AMC PV6 (L062-05) PV8 (L113-03) and PV9 (L209-...            179   \n",
       "10                          Reference\\n8D\\nES19121623             23   \n",
       "11  BMW complained first issues 07/2018 (19.07.) @...            198   \n",
       "12  All BMW plants (using SCR systems) are\\ninfect...            147   \n",
       "13  Failure root cause has\\nto be understood and\\n...            104   \n",
       "14  TFM/System: Drop of pressure partly reproducea...            259   \n",
       "15  Software validation performed and passed. Cali...            173   \n",
       "16  Software validation performed and passed. For ...            170   \n",
       "\n",
       "    input_length                model_name      time  \n",
       "0            266   cut_split_dynamic_false  4.753284  \n",
       "1            189   cut_split_dynamic_false  9.356972  \n",
       "2            109   cut_split_dynamic_false  0.000997  \n",
       "3           1061   cut_split_dynamic_false  5.075427  \n",
       "4            266  uncut_unsplit_80_false_4  4.080085  \n",
       "5            189  uncut_unsplit_80_false_4  4.110008  \n",
       "6            109  uncut_unsplit_80_false_4  1.311477  \n",
       "7           1061  uncut_unsplit_80_false_4  6.824746  \n",
       "8            544  uncut_unsplit_80_false_4  3.422844  \n",
       "9            348  uncut_unsplit_80_false_4  4.434141  \n",
       "10            49  uncut_unsplit_80_false_4  0.768943  \n",
       "11           300  uncut_unsplit_80_false_4  4.297503  \n",
       "12           281  uncut_unsplit_80_false_4  2.552174  \n",
       "13           145  uncut_unsplit_80_false_4  1.603712  \n",
       "14           742  uncut_unsplit_80_false_4  5.255943  \n",
       "15           318  uncut_unsplit_80_false_4  3.105693  \n",
       "16           388  uncut_unsplit_80_false_4  3.019922  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78668855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>output_length</th>\n",
       "      <th>input_length</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [input, output, output_length, input_length, time_taken, model_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [\"input\", \"output\", \"output_length\", \"input_length\", \"model_name\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abcb55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
