{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc159cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import spacy\n",
    "import pytextrank\n",
    "import en_core_web_sm\n",
    "import re\n",
    "import sys\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea667285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7b12a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# punctuation model\n",
    "model_p = PunctuationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a9eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1df1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(files):\n",
    "    \"\"\" returns file names in the folder\"\"\"\n",
    "    file_names = []\n",
    "    for file in files:\n",
    "        file_names.append(glob.glob(file))\n",
    "    file_names = list(itertools.chain.from_iterable(file_names))\n",
    "    return file_names\n",
    "\n",
    "def make_summary_f(text, max_length):\n",
    "    \"\"\" use the facebook model to get a summary\"\"\"\n",
    "    sum_list = summarizer(text, min_length=20, max_length = max_length, do_sample=False)\n",
    "    string = next(iter(sum_list[0].items()))[1]\n",
    "    return string\n",
    "\n",
    "def punct_model(text):\n",
    "    \"\"\"punctuate the text\"\"\"\n",
    "    return(model_p.restore_punctuation(text))\n",
    "\n",
    "def text_rank(text):\n",
    "    \"\"\" use text rank to rank the phrases\"\"\"\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    nlp.add_pipe('textrank', last=True)\n",
    "    doc = nlp(text)\n",
    "    str_arr = []\n",
    "    for string in doc._.textrank.summary(limit_phrases=5, limit_sentences=1):\n",
    "        str_arr.append(string)\n",
    "    return str_arr[0].text\n",
    "\n",
    "def model(text, run_text_rank, fb_length):\n",
    "    \"\"\" run_text_rank is a bool, true if text rank should be\n",
    "        used in the model. Set length for make_summary_f\"\"\"\n",
    "    if run_text_rank:\n",
    "        temp =  text_rank(text)\n",
    "        return make_summary_f(temp,fb_length)\n",
    "    \n",
    "    return make_summary_f(text, fb_length)\n",
    "\n",
    "def short_min(text):\n",
    "    \"\"\"\n",
    "    cut text to first punctuation mark\n",
    "    \"\"\"\n",
    "    symbols = [\".\",\";\"]\n",
    "    arr = []\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    for char in text:\n",
    "        if char in symbols:\n",
    "            counter+=1\n",
    "            arr.append((char, i))\n",
    "        i+=1\n",
    "        \n",
    "    min_val = sys.maxsize\n",
    "    for tup in arr:\n",
    "        if min_val>tup[1]:\n",
    "            min_val = tup[1]\n",
    "    \n",
    "    #if you have a good sentence of the right size return it\n",
    "    return text[0:min_val]\n",
    "\n",
    "def check_str(text,l,u):\n",
    "    \"\"\" give lower and upper bounds and return true or false\n",
    "        if the text is within the range\"\"\"\n",
    "    if text == 0:\n",
    "        return False\n",
    "    elif len(text)<=u and len(text)>=l:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def shorten_string(text):\n",
    "    \"\"\"\n",
    "    cut text to closest punctuation mark to 80 characters\n",
    "    \"\"\"\n",
    "    symbols = [\".\",\";\"]\n",
    "    arr = []\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    #get all locations of the punctuations\n",
    "    for char in text:\n",
    "        if char in symbols:\n",
    "            counter+=1\n",
    "            arr.append((char, i))\n",
    "        i+=1\n",
    "        \n",
    "    min_val = sys.maxsize\n",
    "    for tup in arr:\n",
    "        if min_val>tup[1]:\n",
    "            min_val = tup[1]\n",
    "    \n",
    "    i = 0\n",
    "    up_bound = 0\n",
    "    low_bound = 0\n",
    "    # get punctuations closest to character 90\n",
    "    while i<len(arr):\n",
    "        if up_bound !=0 and low_bound !=0:\n",
    "            break\n",
    "        elif arr[i][1]>=90:\n",
    "            up_bound = arr[i][1]\n",
    "            low_bound = arr[i-1][1]\n",
    "        i+=1\n",
    "    #print(arr)\n",
    "    #print(up_bound, low_bound)\n",
    "    \n",
    "    difu = abs(up_bound-90)\n",
    "    difl = abs(low_bound-90)\n",
    "    diful = up_bound-low_bound\n",
    "    \n",
    "    # if the upper and lower bounds are close\n",
    "    if up_bound !=0:\n",
    "        #shorten to upper bound if the difference between them is small\n",
    "        # or the upper bound is smaller than the lower bound or the lower bound\n",
    "        # is 35 or less\n",
    "        if diful<=5 or difu<=difl or difl<35:\n",
    "            short_string = text[0:up_bound]\n",
    "            return short_string\n",
    "        elif difu>=difl:\n",
    "            short_string = text[0:low_bound]\n",
    "            return short_string\n",
    "    \n",
    "    return text[0:min_val]\n",
    "    \n",
    "def check_stops(text):\n",
    "    \"\"\"return how many full stops in the text\"\"\"\n",
    "    symbols = [\".\"]\n",
    "    counter = 0\n",
    "    for char in text:\n",
    "        if char == \".\":\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def similar(len1, len2):\n",
    "    # find out if 2 texts are similar in length\n",
    "        if abs(len1-len2)<=3:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def cut(a, l, u):\n",
    "    # check if the model gives a suitable summary\n",
    "    #if check_str(a,l,u):\n",
    "    #print(grp + \"1: \" + a)\n",
    "    \n",
    "    # shorten the text to the first punctuation and see if it meets the criteria    \n",
    "    temp_f = short_min(a)\n",
    "    #if check_str(temp_f,l,u):\n",
    "    #print(grp + \"2: \" +temp_f)\n",
    "\n",
    "    # shorten the text to the punctutation mark closest to 90 characters and see if it\n",
    "    # meets the criteria\n",
    "    temp_e = shorten_string(a)\n",
    "    #if check_str(temp_e,l,u):\n",
    "    #print(grp + \"3: \" +temp_e)\n",
    "\n",
    "    # add punctuation to the SHORTENED TEXT to FIRST punctuation. \n",
    "    # shorten it again to the FIRST punctuation and check if it meets the criteria\n",
    "    punct_temp_f = punct_model(temp_f)\n",
    "    temp_fpf = short_min(punct_temp_f)\n",
    "    #if check_str(temp_fpf,l,u):\n",
    "    #print(grp + \"4: \" +temp_fpf)\n",
    "\n",
    "    # add punctuation to the SHORTENED TEXT to FIRST punctuation.\n",
    "    # shorten it again to the 90TH punctuation and check if it meets the criteria\n",
    "    temp_fpe = shorten_string(punct_temp_f)\n",
    "    #if check_str(temp_fpe,l,u):\n",
    "    #print(grp + \"5: \" +temp_fpe)\n",
    "\n",
    "    # add punctuation to the SHORTENED TEXT to 90TH punctuation.\n",
    "    # shorten it again to the FIRST punctuation and check if it meets the criteria\n",
    "    punct_temp_e = punct_model(temp_e)\n",
    "    temp_epf = short_min(punct_temp_e)\n",
    "    #if check_str(temp_epf,l,u):\n",
    "    #print(grp + \"6: \" +temp_epf)\n",
    "\n",
    "    # add punctuation to the SHORTHENED TEXT to 90TH punctuation.\n",
    "    # shorten it again to the 80TH punctuation and check if it meets the criteria\n",
    "    temp_epe = shorten_string(punct_temp_e)\n",
    "    #if check_str(temp_epe,l,u):\n",
    "    #print(grp + \"7: \" +temp_epe)\n",
    "\n",
    "    # add punctuaction to the TEXT and shorten it to the FIRST punctuation\n",
    "    punct_temp_t = punct_model(a)\n",
    "    temp_tpf = short_min(punct_temp_t)\n",
    "    #if check_str(temp_tpf,l,u):\n",
    "    #print(grp + \"8: \" +temp_tpf)\n",
    "\n",
    "    # add punctuation to the TEXT and shorten it to the 90TH punctuation\n",
    "    temp_tpe = shorten_string(punct_temp_t)\n",
    "    #if check_str(temp_tpe,l,u):\n",
    "    #print(grp + \"9: \" +temp_tpe)\n",
    "    \n",
    "    summaries = []\n",
    "    lengths = []\n",
    "    summaries.extend([a, temp_f, temp_e, temp_fpf, temp_fpe, temp_epf, temp_epe, temp_tpf, temp_tpe])\n",
    "    lengths.extend([len(a), len(temp_f), len(temp_e), len(temp_fpf), len(temp_fpe), len(temp_epf)\n",
    "                    , len(temp_epe), len(temp_tpf), len(temp_tpe)])\n",
    "    \n",
    "    summaries.sort()\n",
    "    lengths.sort()\n",
    "    i = len(summaries)-1\n",
    "    while i>0:\n",
    "        if not similar(lengths[i],lengths[8]) and check_str(summaries[i],l,u):\n",
    "            #print(i)\n",
    "            return str(summaries[i])\n",
    "        elif not similar(lengths[i],lengths[8]) or check_str(summaries[i],l,u):\n",
    "            #print(i)\n",
    "            return str(summaries[i])\n",
    "        i-=1\n",
    "    \n",
    "    return str(summaries[8])\n",
    "\n",
    "def check_length(text, length):\n",
    "    \"\"\"keep input string length between 300-400 words\"\"\"\n",
    "    return text[0:length]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "751d6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [\"Json files/*.json\"]\n",
    "json_files = get_filenames(path)\n",
    "i=0\n",
    "length = 2500\n",
    "desc = \"PROBLEM DESCRIPTION \"\n",
    "target = \"TARGET CONDITION \"\n",
    "current = \"CURRENT CONDITION \"\n",
    "root = \"ROOT CAUSE ANALYSIS \"\n",
    "counter = \"COUNTERMEASURES \"\n",
    "effect = \"EFFECT CONFIRMATION \"\n",
    "follow = \"FOLLOW UP ACTION \"\n",
    "long_strs = []\n",
    "#print(len(json_files))\n",
    "while i < len(json_files):\n",
    "    f = open(json_files[i])\n",
    "    dicts = json.load(f)\n",
    "    for vals in dicts.values():\n",
    "        for val in vals.items():\n",
    "            l = 40\n",
    "            u = 150\n",
    "            if val[0] == \"PROBLEM DESCRIPTION\":\n",
    "                desc += val[1]\n",
    "            elif val[0] == \"TARGET CONDITION\":\n",
    "                target+=val[1]\n",
    "            elif val[0] == \"CURRENT CONDITION\":\n",
    "                current += val[1]\n",
    "            elif val[0] == \"ROOT CAUSE ANALYSIS\":\n",
    "                root+=val[1]\n",
    "            elif val[0] == \"COUNTERMEASURES\":\n",
    "                counter +=val[1]\n",
    "            elif val[0] == \"EFFECT CONFIRMATION\":\n",
    "                effect+=val[1]\n",
    "            elif val[0] == \"FOLLOW UP ACTION\":\n",
    "                follow+=val[1]\n",
    "                #g.write(\"\\n\")\n",
    "                #a = model(val[1], False, 53)\n",
    "                #g.write(cut(a,l,u,val[0]))\n",
    "    i+=1\n",
    "#print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a77df22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEM DESCRIPTION WO# K150-08, Deka 10 TP1008 DV dynamic lean shift failure observed In RSG E-10 test bench mechanical durability per S1297 Injectors were manufactured in Prototype Services May 29, 2019. Configuration: 12.55mm OD,Extra Short, 10mm Tip, Schaleger MPG, NPN ATB, NPN LSSBMW complained first issues 07/2018 (19.07.) @plant Dingolfing (Hr. Habold MUC). There're no specific OBD failure code. The failure appears after first SCR system initiation (F1_Test). Failed at test step: System leak test. Service 31 ID 0x301 Detailed failure description see attachment (EINFÜGEN!).1) What vehicle CN7/CN7a 2) Product SIM3K-541, SW version 6VA600 3) Who issued HMMA QC 4) How HMMA QC reported that '5' instead of 'D' was displayed for the select lever switch information via UDS $22 in Roll &Brake process of CN7 vehicle. And compared to the project Nu ATK CVT, different value was displayed for D range. 5) Containment action 9,124EA to be reprogrammed in HMMA plantInjectors mechanically inoperable after 400 cycles of thermal shock, functional issues noted since 100 cycles TP 7072: M084U28120 M084U29625, TP7363: M085K27336 Containment Action - NPN - within Validation09.07. BMW (Rolls Royce) communicated an issue @plant Goodwood. Problem only with D-sample ECU together with 18-07-530 B88 software and affected datasets concerning the synchronization of the immobilizer (EWS elektronische Wegfahrsperre); key is not writeable with any tooling anymore. Further investigation showed that the re-programming of the ECU (MSD87 - 12 cylinder) is not possible anymore for some dataset variants of the SW B88 (e.g.: RR4 US BB / RR5 US / RR6 US BB).Spray angle ranging from 36,7° to 69,0°O PV parts (spec allow 70°+25°)When: On Dec.5th.2018, CAF CQ3 found one piece injector stuck open during vehicle testing. What: The chips from VB was found in the seat sealing area after tear down injector on Dec. 11st.2018 Which supplier of VB: Asimco Beijing Picture 1 2 - Containment action: Dec.10th.2018: Fast response to customer and send back the suspected part. 100% VB sorting in CGQ plant and supplier side. No chips part wasSporadic CAN frame dropouts existing in Pre-SW-versions of SE1500. This leads to a sporadic dropout of Message ESP21 and triggers toggling of vs SAE (raw value of vehicle speed), which leads to alternating values between 0 and 255 (replacement/substitute value).\n",
      "TARGET CONDITION Twenty four of twenty-four injectors successfully pass test bench mechanical durability per S1297 in RSG E-10Failure root cause has to be understood and failure occurrence has to be eliminated. Target is to bring F1_testfails to zero % at customer plants1) Target Customer requirement delivered at Nu ATK project $01A0 in UDS $22 service D is defined by '8'. Select Lever Switch Displayed via GDS after changing Manual Mode 12- Product functionality remains post air-air thermal shock testingGoal is to analyze the ECU hardware and the affected B88 software and the calibration data to fix both issues (immobilizer sync & reprogramming).All parts produced within 70°+25° specificationConfirm the root cause in supplier side and implement prevention action in production line. B. Find Root cause of Problem / IssueIdentify the root cause of CAN frame / ESP21 dropouts and the the location of the failure (VT side or VW side). If failure is on VT side define timing for problem solution (SW correction) and allign it with overall SW timing for SE1500/SE1550, depending on severity of the problem\n",
      "CURRENT CONDITION Specification (+5% / -3%) 200M Audit: 47362 = -10.1%, 47371 = -6.2%, 47384 = -6.1% 300M Audit: 4742 2= -6.7%, 47421 = -3.3% *Reference 8D ES191216231144 for additional dynamic lean failuresAll BMW plants (using SCR systems) are infected, also all variants (using SCR system). After some minutes the test can be repeated without the failure. BMW decided to send the cars out. Just one system affected were the second test was also not ok. this system will be send to RGB.1) Current $01A0 in UDS $22 service D is defined by '5'. Lever Switch Displayed via GDS before changing 2) Impact: Roll and brake test in customer plant cannot be passed due to wrong gear information from TCUDeka 7 transfer for CGQ Thermal Shock test S1331 500 Shocks; Qd +4/-4% Shift from baseline TP7072 - ER1149 (WO#M123-02), TP7363 - ER1150 (WO#M123-08) Short Standard tipInitial status: An analysis of locked ECUs showed that only SW variants which have an activated anti jerk function are affected. BMW Customer part#: 9453018-01 (SW 9SP9B88S) Upd. 13th of July: Customer updated all data variants of the SW B88 with calibration workaround and deactivated anti jerk function. Upd. 18th of July: One cycle resume command of the controller enable the flash protection during start up and locked the ECU; SW update planned for SW C00 in CW31 (activation of anti jerk is possible again).Out of specification spray angle for DDU transfer PV parts, Specification allows 70°+25°, parts observed as low as 36° Situation pertains to both GM and HMC parts produced for transfer PV, but not to Ford parts No containment needed - parts not being produced for customer, only for PVSporadic CAN frame dropouts existing in Pre-SW-versions of SE1 Delivery of SW SE1500 to customer VW stopped\n",
      "ROOT CAUSE ANALYSIS Reference 8D ES 191216231144 for detailed analysis of root cause hypotheses of design robustness RCH2 - Deka 10 design and process variation introduces inherent variability, resulting in isolated occurrences dynamic lean shift observation Why does dynamic lean shift occur in a percentage of the test population? Dynamic lean shift occurs due to an increase in opening time, and variation in opening time is seen part to part Why does opening time variation occur? Opening time variation is a resultant of variation in wear severity at the sealing interface Why is variation seen in ball to seat sealing band wear? Wear variation is a resultant of design robustness sensitivity to design and process parameter variation Why was variation of design and process parameters influence on dynamic shift not captured in Deka 10 CTG 8D S180711224450? Overall variation in small controlled builds not captured, resulting in small occurrence of flow shift being observed outside of the defined specification due to sensitivity and lack of robustness against the stack-upComponents/systems analysis: TFM/System: Drop of pressure partly reproduceable at RBG testbench since 28.09.2018, but pressure values are still in tolerance and therefore the system leaktest is passed. During this test only the returned TFM was used and therefore the rootcause could be located to the TFM module. RDU: First part was NTF; cleanliness analysis t.b.d CW 40 To be clarified Is there any connection between failure re-occurrence and time between first and second Components analysis in consideration of failure description (leakage, damages, Full pump characterization cw40 to locate source of symptom Optimization of BMW test to be proved. Please consider the additional \"fault tree file\" and presentation ,,DD additional docs\".in Nu ATK CVT Spec was only SWCN canceled Why Why Why Wrong managem spec and sw) wrong value was not set back value from $22 service Spec ewed was with not revi reference for UDS Why for not used to review er requirement 6VA project Customer require d based on spec for the test- RCH1: Handling damage - No visual damage found on inspection Not RCH RCH2: Issue with Exsol D40 used as calibration fluid Not RCH (review FTIR results) RCH3 Contamination introduced in assembly process -> Not RCH Injector M085K27336 was sumberged in n-Heptane for 24 hours, post soak injector returned to nominal flow values RCH4: Fluid introduced post injector assembly Primary RCH RCH4.1: Functional Bench Fluid - Not RCH RCH4.2: O-ring lubrication -> Confirmed RCH Mineral oil confirmed to match residue observed within stuck injectors IN-062802/IN-062803 (cell 6/cell 7) instructs technician to lightly lubricate upper injector oring prior to insertion in test headTrigger is \"anti jerk\" function that activates flash protection and it is not possible to reprogram the ECU Only D-samples (serial parts) are affected. Some flash containers of SW version B86 to B88 show this behavior (BMW stated). Continental analysis of the various effected vehicle variants (e.g.: RR4 US BB / RR5 US / RR6 US BB) gave a hint to some special calibration data variant (activation of anti jerk function). BMW confirmed this finding with a crosscheck (deactivation of anti jerk function) in an affected calibration variant. To understand the root cause debugging of a D-sample ECU is necessary. A new ECU with Lauterbach access has to be built up for debugging. A changed S-Boot is necessary for debugger access. Switch is necessary to disable the Monitoring Unit (MU) and the Watchdog (WD). Debugging showed an issue that occurs due to copy process of the flash memory which is necessary for application ECUs but not for serial ECU samples. This process caused an Single Cycle Resume Command, which enables the Flash Protection. Therefore at least on one of the four addresses A0045554 / A0055554 A0065554 / A0075554 must have the value \"5E\" so that the flash protection is activated. One of these four addresses is used by the anti jerk function.Supplier change for DDU lower housing (LH) (NPN components Texeido) and obsolete machinery used to produce the part resulted in the update of certain LH print dimensions to reduce leak failures. This resulted in a valve that was more recessed inside the LH than normal NPN production parts and the risk of having some parts out of spec for spray cone angle. )These parts are identified as Loop 1) This issue was able to be turned on and off by varying the amount by which the valve wasCause 1: One pcs of debug part was mixed into good parts by debug technician. Check the FTQ ( scrap record), only one piece (chips defect) part is missed in the record. Suspect part was produced on Jun.26.2018 in supplier side, the equipment manufacturer did the annual calibration on that day according to record on that day. Cause 2: Incorrect the length of drilling tool during debug Repeat the same failure mode with incorrect length 53.29mm of drilling tool The chip occur after change the length of tool. Cause 3: Visual check WI did not clearly specify this defect location and boundary samples. There are risky the operator skip the NG part during inspection. A al inspection operator A Cleaning operator Final inspector miss the defect part Cleaning process External technician mix the debug part VB chip (Why happened?( (Occur path)Debugging Session identifies that the restbus simulation, delivery from customer VW, is the main root cause for toggling of the ESP_21 Message. Here the ESP_21 message is sent 3 times in a row within timing of overall - 10ms. Regular/correct case would be here that a message transfer every 20ms is present (only one event/message per 20ms). @ - 412317 CAN E4 ESP_21_SOK_Signatur_SOK_XIX_E3V_ACANFD 429913 CAN FD SP_21_XIX_E3V_ACANFD 430361 CAN : E4 ESP_21_SOK_Signatur_SOK_XIX_E3V_ACANFI 449567 CAN 1 FD ESP_21_XIX__E3V_ACANFD CAN 1 E4 ICAS(TX) ASG 2.2 (RX): Message CAN ESP_21_XIX_E3V_ACANFD ICAS(TX) Message CAN FD SP_21_XIX_E3V_ACANFD ICAS(TX) ASG 2.2 (RX): Message ICAS(TX) ASG 2.2 (RX): Signature 1 ICAS(TX ASG 2.2 (RX): Signature 2 19.531318 E4 ICAS(TX) ASG 2.2 (RX): Signature 3 19.533198 CAN 1 E4 CAN : FD ESP_21_XIX_E3V_ACANFD 19.535459 CAN 1 E4 ESP_21_SOK_Signatur_SOK_XIX_E3V_ACAN CAN 1 FD ESP_21_XIX_E3V_ACANFD 19.551877 CAN 1 E4 ESP_21_SOK_Signatur_SOK_XIX_E3V_ACANFD\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n\u001b[0;32m      9\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[1;32m---> 10\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m g\u001b[38;5;241m.\u001b[39mwrite(cut(a,l,u))\n\u001b[0;32m     12\u001b[0m g\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [18], line 36\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m(text, run_text_rank, fb_length)\u001b[0m\n\u001b[0;32m     33\u001b[0m     temp \u001b[38;5;241m=\u001b[39m  text_rank(text)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m make_summary_f(temp,fb_length)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_summary_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfb_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [18], line 11\u001b[0m, in \u001b[0;36mmake_summary_f\u001b[1;34m(text, max_length)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_summary_f\u001b[39m(text, max_length):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124;03m\"\"\" use the facebook model to get a summary\"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     sum_list \u001b[38;5;241m=\u001b[39m \u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(sum_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()))[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m string\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:235\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:137\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m    142\u001b[0m     ):\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1074\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1080\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1081\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1082\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m    989\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 990\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m    991\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:159\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_length)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m], generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 159\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    160\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_utils.py:1207\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[0;32m   1201\u001b[0m         inputs_tensor, pad_token_id, eos_token_id\n\u001b[0;32m   1202\u001b[0m     )\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;66;03m# 4. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_utils.py:524\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[0;32m    522\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    523\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 524\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:803\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[1;32m--> 803\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n\u001b[0;32m    806\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm_embedding(hidden_states)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:139\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[1;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[0;32m    134\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    135\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m    136\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    137\u001b[0m )\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2195\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "long_strs = np.array([desc, target, current, root, counter, effect, follow])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with open('jsons.txt', 'a') as g:\n",
    "    for string in long_strs:\n",
    "        print(string)\n",
    "        l = 40\n",
    "        u = 150\n",
    "        a = model(string, False, 200)\n",
    "        g.write(cut(a,l,u))\n",
    "        g.write(\"\\n\")\n",
    "f.close()\n",
    "end = time.time()\n",
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea1d58cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([desc, target])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344d8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
