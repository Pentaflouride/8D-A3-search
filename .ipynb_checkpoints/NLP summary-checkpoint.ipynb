{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc159cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import spacy\n",
    "import pytextrank\n",
    "import en_core_web_sm\n",
    "import re\n",
    "import sys\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea667285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7b12a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# punctuation model\n",
    "model_p = PunctuationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a9eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1df1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(files):\n",
    "    \"\"\" returns file names in the folder\"\"\"\n",
    "    file_names = []\n",
    "    for file in files:\n",
    "        file_names.append(glob.glob(file))\n",
    "    file_names = list(itertools.chain.from_iterable(file_names))\n",
    "    return file_names\n",
    "\n",
    "def make_summary_f(text, max_length):\n",
    "    \"\"\" use the facebook model to get a summary\"\"\"\n",
    "    sum_list = summarizer(text, min_length=20, max_length = max_length, do_sample=False)\n",
    "    string = next(iter(sum_list[0].items()))[1]\n",
    "    return string\n",
    "\n",
    "def punct_model(text):\n",
    "    \"\"\"punctuate the text\"\"\"\n",
    "    return(model_p.restore_punctuation(text))\n",
    "\n",
    "def text_rank(text):\n",
    "    \"\"\" use text rank to rank the phrases\"\"\"\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    nlp.add_pipe('textrank', last=True)\n",
    "    doc = nlp(text)\n",
    "    str_arr = []\n",
    "    for string in doc._.textrank.summary(limit_phrases=5, limit_sentences=1):\n",
    "        str_arr.append(string)\n",
    "    return str_arr[0].text\n",
    "\n",
    "def model(text, run_text_rank, fb_length):\n",
    "    \"\"\" run_text_rank is a bool, true if text rank should be\n",
    "        used in the model. Set length for make_summary_f\"\"\"\n",
    "    if run_text_rank:\n",
    "        temp =  text_rank(text)\n",
    "        return make_summary_f(temp,fb_length)\n",
    "    \n",
    "    return make_summary_f(text, fb_length)\n",
    "\n",
    "def short_min(text):\n",
    "    \"\"\"\n",
    "    cut text to first punctuation mark\n",
    "    \"\"\"\n",
    "    symbols = [\".\",\";\"]\n",
    "    arr = []\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    for char in text:\n",
    "        if char in symbols:\n",
    "            counter+=1\n",
    "            arr.append((char, i))\n",
    "        i+=1\n",
    "        \n",
    "    min_val = sys.maxsize\n",
    "    for tup in arr:\n",
    "        if min_val>tup[1]:\n",
    "            min_val = tup[1]\n",
    "    \n",
    "    #if you have a good sentence of the right size return it\n",
    "    return text[0:min_val]\n",
    "\n",
    "def check_str(text,l,u):\n",
    "    \"\"\" give lower and upper bounds and return true or false\n",
    "        if the text is within the range\"\"\"\n",
    "    if text == 0:\n",
    "        return False\n",
    "    elif len(text)<=u and len(text)>=l:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def shorten_string(text):\n",
    "    \"\"\"\n",
    "    cut text to closest punctuation mark to 80 characters\n",
    "    \"\"\"\n",
    "    symbols = [\".\",\";\"]\n",
    "    arr = []\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    #get all locations of the punctuations\n",
    "    for char in text:\n",
    "        if char in symbols:\n",
    "            counter+=1\n",
    "            arr.append((char, i))\n",
    "        i+=1\n",
    "        \n",
    "    min_val = sys.maxsize\n",
    "    for tup in arr:\n",
    "        if min_val>tup[1]:\n",
    "            min_val = tup[1]\n",
    "    \n",
    "    i = 0\n",
    "    up_bound = 0\n",
    "    low_bound = 0\n",
    "    # get punctuations closest to character 90\n",
    "    while i<len(arr):\n",
    "        if up_bound !=0 and low_bound !=0:\n",
    "            break\n",
    "        elif arr[i][1]>=90:\n",
    "            up_bound = arr[i][1]\n",
    "            low_bound = arr[i-1][1]\n",
    "        i+=1\n",
    "    #print(arr)\n",
    "    #print(up_bound, low_bound)\n",
    "    \n",
    "    difu = abs(up_bound-90)\n",
    "    difl = abs(low_bound-90)\n",
    "    diful = up_bound-low_bound\n",
    "    \n",
    "    # if the upper and lower bounds are close\n",
    "    if up_bound !=0:\n",
    "        #shorten to upper bound if the difference between them is small\n",
    "        # or the upper bound is smaller than the lower bound or the lower bound\n",
    "        # is 35 or less\n",
    "        if diful<=5 or difu<=difl or difl<35:\n",
    "            short_string = text[0:up_bound]\n",
    "            return short_string\n",
    "        elif difu>=difl:\n",
    "            short_string = text[0:low_bound]\n",
    "            return short_string\n",
    "    \n",
    "    return text[0:min_val]\n",
    "    \n",
    "def check_stops(text):\n",
    "    \"\"\"return how many full stops in the text\"\"\"\n",
    "    symbols = [\".\"]\n",
    "    counter = 0\n",
    "    for char in text:\n",
    "        if char == \".\":\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def similar(len1, len2):\n",
    "    # find out if 2 texts are similar in length\n",
    "        if abs(len1-len2)<=3:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def cut(a, l, u, grp):\n",
    "    # check if the model gives a suitable summary\n",
    "    #if check_str(a,l,u):\n",
    "    #print(grp + \"1: \" + a)\n",
    "    \n",
    "    # shorten the text to the first punctuation and see if it meets the criteria    \n",
    "    temp_f = short_min(a)\n",
    "    #if check_str(temp_f,l,u):\n",
    "    #print(grp + \"2: \" +temp_f)\n",
    "\n",
    "    # shorten the text to the punctutation mark closest to 90 characters and see if it\n",
    "    # meets the criteria\n",
    "    temp_e = shorten_string(a)\n",
    "    #if check_str(temp_e,l,u):\n",
    "    #print(grp + \"3: \" +temp_e)\n",
    "\n",
    "    # add punctuation to the SHORTENED TEXT to FIRST punctuation. \n",
    "    # shorten it again to the FIRST punctuation and check if it meets the criteria\n",
    "    punct_temp_f = punct_model(temp_f)\n",
    "    temp_fpf = short_min(punct_temp_f)\n",
    "    #if check_str(temp_fpf,l,u):\n",
    "    #print(grp + \"4: \" +temp_fpf)\n",
    "\n",
    "    # add punctuation to the SHORTENED TEXT to FIRST punctuation.\n",
    "    # shorten it again to the 90TH punctuation and check if it meets the criteria\n",
    "    temp_fpe = shorten_string(punct_temp_f)\n",
    "    #if check_str(temp_fpe,l,u):\n",
    "    #print(grp + \"5: \" +temp_fpe)\n",
    "\n",
    "    # add punctuation to the SHORTENED TEXT to 90TH punctuation.\n",
    "    # shorten it again to the FIRST punctuation and check if it meets the criteria\n",
    "    punct_temp_e = punct_model(temp_e)\n",
    "    temp_epf = short_min(punct_temp_e)\n",
    "    #if check_str(temp_epf,l,u):\n",
    "    #print(grp + \"6: \" +temp_epf)\n",
    "\n",
    "    # add punctuation to the SHORTHENED TEXT to 90TH punctuation.\n",
    "    # shorten it again to the 80TH punctuation and check if it meets the criteria\n",
    "    temp_epe = shorten_string(punct_temp_e)\n",
    "    #if check_str(temp_epe,l,u):\n",
    "    #print(grp + \"7: \" +temp_epe)\n",
    "\n",
    "    # add punctuaction to the TEXT and shorten it to the FIRST punctuation\n",
    "    punct_temp_t = punct_model(a)\n",
    "    temp_tpf = short_min(punct_temp_t)\n",
    "    #if check_str(temp_tpf,l,u):\n",
    "    #print(grp + \"8: \" +temp_tpf)\n",
    "\n",
    "    # add punctuation to the TEXT and shorten it to the 90TH punctuation\n",
    "    temp_tpe = shorten_string(punct_temp_t)\n",
    "    #if check_str(temp_tpe,l,u):\n",
    "    #print(grp + \"9: \" +temp_tpe)\n",
    "    \n",
    "    summaries = []\n",
    "    lengths = []\n",
    "    summaries.extend([a, temp_f, temp_e, temp_fpf, temp_fpe, temp_epf, temp_epe, temp_tpf, temp_tpe])\n",
    "    lengths.extend([len(a), len(temp_f), len(temp_e), len(temp_fpf), len(temp_fpe), len(temp_epf)\n",
    "                    , len(temp_epe), len(temp_tpf), len(temp_tpe)])\n",
    "    \n",
    "    summaries.sort()\n",
    "    lengths.sort()\n",
    "    i = len(summaries)-1\n",
    "    while i>0:\n",
    "        if not similar(lengths[i],lengths[8]) and check_str(summaries[i],l,u):\n",
    "            #print(i)\n",
    "            return str(grp + \": \" + summaries[i])\n",
    "        elif not similar(lengths[i],lengths[8]) or check_str(summaries[i],l,u):\n",
    "            #print(i)\n",
    "            return str(grp + \": \" + summaries[i])\n",
    "        i-=1\n",
    "    \n",
    "    return str(grp + \": \" + summaries[8])\n",
    "\n",
    "def check_length(text, length):\n",
    "    \"\"\"keep input string length between 300-400 words\"\"\"\n",
    "    return text[0:length]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "751d6d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEM DESCRIPTION WO# K150-08, Deka 10 TP1008 DV dynamic lean shift failure observed In RSG E-10 test bench mechanical durability per S1297 Injectors were manufactured in Prototype Services May 29, 2019. Configuration: 12.55mm OD,Extra Short, 10mm Tip, Schaleger MPG, NPN ATB, NPN LSSBMW complained first issues 07/2018 (19.07.) @plant Dingolfing (Hr. Habold MUC). There're no specific OBD failure code. The failure appears after first SCR system initiation (F1_Test). Failed at test step: System leak test. Service 31 ID 0x301 Detailed failure description see attachment (EINFÜGEN!).1) What vehicle CN7/CN7a 2) Product SIM3K-541, SW version 6VA600 3) Who issued HMMA QC 4) How HMMA QC reported that '5' instead of 'D' was displayed for the select lever switch information via UDS $22 in Roll &Brake process of CN7 vehicle. And compared to the project Nu ATK CVT, different value was displayed for D range. 5) Containment action 9,124EA to be reprogrammed in HMMA plantInjectors mechanically inoperable after 400 cycles of thermal shock, functional issues noted since 100 cycles TP 7072: M084U28120 M084U29625, TP7363: M085K27336 Containment Action - NPN - within Validation09.07. BMW (Rolls Royce) communicated an issue @plant Goodwood. Problem only with D-sample ECU together with 18-07-530 B88 software and affected datasets concerning the synchronization of the immobilizer (EWS elektronische Wegfahrsperre); key is not writeable with any tooling anymore. Further investigation showed that the re-programming of the ECU (MSD87 - 12 cylinder) is not possible anymore for some dataset variants of the SW B88 (e.g.: RR4 US BB / RR5 US / RR6 US BB).Spray angle ranging from 36,7° to 69,0°O PV parts (spec allow 70°+25°)When: On Dec.5th.2018, CAF CQ3 found one piece injector stuck open during vehicle testing. What: The chips from VB was found in the seat sealing area after tear down injector on Dec. 11st.2018 Which supplier of VB: Asimco Beijing Picture 1 2 - Containment action: Dec.10th.2018: Fast response to customer and send back the suspected part. 100% VB sorting in CGQ plant and supplier side. No chips part wasSporadic CAN frame dropouts existing in Pre-SW-versions of SE1500. This leads to a sporadic dropout of Message ESP21 and triggers toggling of vs SAE (raw value of vehicle speed), which leads to alternating values between 0 and 255 (replacement/substitute value).\n",
      "The time of execution of above program is : 0.04491376876831055\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "path = [\"Json files/*.json\"]\n",
    "json_files = get_filenames(path)\n",
    "i=0\n",
    "length = 2500\n",
    "desc = \"PROBLEM DESCRIPTION \"\n",
    "target = \"TARGET CONDITION \"\n",
    "current = \"CURRENT CONDITION \"\n",
    "root = \"ROOT CAUSE ANALYSIS \"\n",
    "counter = \"COUNTERMEASURES \"\n",
    "effect = \"EFFECT CONFIRMATION \"\n",
    "follow = \"FOLLOW UP ACTION \"\n",
    "\n",
    "#print(len(json_files))\n",
    "with open('jsons4.0.txt', 'a') as g:\n",
    "    while i < len(json_files):\n",
    "        f = open(json_files[i])\n",
    "        dicts = json.load(f)\n",
    "        for vals in dicts.values():\n",
    "            for val in vals.items():\n",
    "                l = 40\n",
    "                u = 150\n",
    "                if val[0] == \"PROBLEM DESCRIPTION\":\n",
    "                    desc += val[1]\n",
    "                elif val[0] == \"TARGET CONDITION\":\n",
    "                    target+=val[1]\n",
    "                elif val[0] == \"CURRENT CONDITION\":\n",
    "                    current += val[1]\n",
    "                elif val[0] == \"ROOT CAUSE ANALYSIS\":\n",
    "                    root+=val[1]\n",
    "                elif val[0] == \"COUNTERMEASURES\":\n",
    "                    counter +=val[1]\n",
    "                elif val[0] == \"EFFECT CONFIRMATION\":\n",
    "                    effect+=val[1]\n",
    "                elif val[0] == \"FOLLOW UP ACTION\":\n",
    "                    follow+=val[1]\n",
    "                    #while len(string) < length:\n",
    "                    #    print(len(string))\n",
    "                    #    string+=val[0]+ \": \"+val[1]\n",
    "                    #g.write(\"\\n\")\n",
    "                    #a = model(val[1], False, 53)\n",
    "                    #g.write(cut(a,l,u,val[0]))\n",
    "        i+=1\n",
    "print(desc)\n",
    "f.close()\n",
    "end = time.time()\n",
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "path = [\"Json files/*.json\"]\n",
    "json_files = get_filenames(path)\n",
    "i=0\n",
    "length = 2500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
