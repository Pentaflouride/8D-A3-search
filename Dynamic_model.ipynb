{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83285635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import textwrap\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75d7ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "condi_gen = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d981c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summary():\n",
    "    def __init__(self,text,l,u,beams,stop,skip):\n",
    "        \"\"\"\n",
    "        l - lower bound of the string as a float below 1\n",
    "        u - upper bound of the string as a float below 1 always greater than l\n",
    "        beams -  number of beams as an int\n",
    "        stop - true or false for early stopping\n",
    "        skip - true or false for skipping special characters\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.output = \"\"\n",
    "        self.l = l\n",
    "        self.u = u\n",
    "        self.beams = beams\n",
    "        self.stop = stop\n",
    "        self.skip = skip\n",
    "        self.name = str(self.l) +str(\"_\")+ str(self.u) +str(\"_\") + str(self.beams) +str(\"_\") + str(self.stop) +str(\"_\") + str(self.skip)\n",
    "        \n",
    "    def new_model(self):\n",
    "\n",
    "        input_tokens = tokenizer.batch_encode_plus([self.text], return_tensors = \"pt\", max_length = 1024, truncation =True)[\"input_ids\"]\n",
    "        num_token = input_tokens.shape[1]\n",
    "        min_ = int(self.l*num_token)\n",
    "        max_ = int(self.u*num_token)\n",
    "\n",
    "        encoded_ids = condi_gen.generate(input_tokens, max_length = max_, min_length = min_, num_beams = self.beams,\n",
    "                                    early_stopping = self.stop)\n",
    "        summary = tokenizer.decode(encoded_ids.squeeze(), skip_special_tokens = self.skip)\n",
    "        self.output = textwrap.fill(summary,max_)\n",
    "        return textwrap.fill(summary,max_)\n",
    "    \n",
    "    \n",
    "\n",
    "def get_filenames(files):\n",
    "    \"\"\" returns file names in the folder\"\"\"\n",
    "    file_names = []\n",
    "    for file in files:\n",
    "        file_names.append(glob.glob(file))\n",
    "    file_names = list(itertools.chain.from_iterable(file_names))\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b051846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run this once\n",
    "df = pd.DataFrame(columns = [\"input\", \"output\", \"output_length\", \"input_length\", \"percentage_decrease\", \"model_name\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89fe3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep running this to fill the dataframe with different hypyer-parameters\n",
    "path = [\"Json files/*.json\"]\n",
    "json_files = get_filenames(path)\n",
    "\n",
    "i=0\n",
    "with open('jsons2.txt', 'a') as g:\n",
    "    while i < len(json_files):\n",
    "        f = open(json_files[i])\n",
    "        dicts = json.load(f)\n",
    "        for vals in dicts.values():\n",
    "            for val in vals.items():\n",
    "                if val[0] == \"PROBLEM DESCRIPTION\" or val[0] == \"TARGET CONDITION\" or val[0] == \"CURRENT CONDITION\" or val[0] == \"ROOT CAUSE ANALYSIS\" or val[0] == \"COUNTERMEASURES\" or val[0] == \"EFFECT CONFIRMATION\" or val[0] == \"FOLLOW UP ACTION\":\n",
    "                    start = time.time()\n",
    "                    sum_ = Summary(val[1],0.3,0.5,2,False,True)\n",
    "                    if len(val[1])<5:\n",
    "                        continue\n",
    "                    a = sum_.new_model()\n",
    "                    #print(a)\n",
    "                    \n",
    "                    end =  time.time()\n",
    "                    df.loc[len(df)] = [val[1], a, len(a), len(val[1]), (len(val[1])-len(a))/len(val[1]),  sum_.name, end-start]\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43349d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aca64bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ce0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
